{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84d079e4-93e8-460d-9d95-54a3fa326ca1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 1: Set the data location and type\n",
    "\n",
    "There are two ways to access Azure Blob storage: account keys and shared access signatures (SAS).\n",
    "\n",
    "To get started, we need to set the location and type of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c760fc54-dbf0-4715-8df6-8fdff699c029",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_account_name = \"devassignment\"\n",
    "storage_account_access_key = \"8YpOLSWDJegnOVlvZzuFpwShdoAPmZpc5Ws4PTz4w6R7sN4WCD+9JgNTs00YgQTxjNfmWVokZ5AE+ASthmNG3g==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_location = \"wasbs://capstone@devassignment.blob.core.windows.net/data/processed/iris_processed.parquet\"\n",
    "file_type = \"parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8acc0dda-69e3-4817-bf5d-450562afe113",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "  \"fs.azure.account.key.\"+storage_account_name+\".blob.core.windows.net\",\n",
    "  storage_account_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51114086-25f5-4c9c-8bb3-64ff28b0f0f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 2: Read the data\n",
    "\n",
    "Now that we have specified our file metadata, we can create a DataFrame. Notice that we use an *option* to specify that we want to infer the schema from the file. We can also explicitly set this to a particular schema if we have one already.\n",
    "\n",
    "First, let's create a DataFrame in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6366891-7da1-478e-8094-4291f4fca976",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_tfm = spark.read.format(file_type).option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b76ff37-cee3-48c5-80e9-a5a79df94b3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+--------+--------------------+\n| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|Species1|            features|\n+---+-------------+------------+-------------+------------+-----------+--------+--------------------+\n|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|     0.0|[1.0,5.1,3.5,1.4,...|\n|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|     0.0|[2.0,4.9,3.0,1.4,...|\n|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|     0.0|[3.0,4.7,3.2,1.3,...|\n|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|     0.0|[4.0,4.6,3.1,1.5,...|\n|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|     0.0|[5.0,5.0,3.6,1.4,...|\n|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|     0.0|[6.0,5.4,3.9,1.7,...|\n|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|     0.0|[7.0,4.6,3.4,1.4,...|\n|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|     0.0|[8.0,5.0,3.4,1.5,...|\n|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|     0.0|[9.0,4.4,2.9,1.4,...|\n| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|     0.0|[10.0,4.9,3.1,1.5...|\n| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|     0.0|[11.0,5.4,3.7,1.5...|\n| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|     0.0|[12.0,4.8,3.4,1.6...|\n| 13|          4.8|         3.0|          1.4|         0.1|Iris-setosa|     0.0|[13.0,4.8,3.0,1.4...|\n| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|     0.0|[14.0,4.3,3.0,1.1...|\n| 15|          5.8|         4.0|          1.2|         0.2|Iris-setosa|     0.0|[15.0,5.8,4.0,1.2...|\n| 16|          5.7|         4.4|          1.5|         0.4|Iris-setosa|     0.0|[16.0,5.7,4.4,1.5...|\n| 17|          5.4|         3.9|          1.3|         0.4|Iris-setosa|     0.0|[17.0,5.4,3.9,1.3...|\n| 18|          5.1|         3.5|          1.4|         0.3|Iris-setosa|     0.0|[18.0,5.1,3.5,1.4...|\n| 19|          5.7|         3.8|          1.7|         0.3|Iris-setosa|     0.0|[19.0,5.7,3.8,1.7...|\n| 20|          5.1|         3.8|          1.5|         0.3|Iris-setosa|     0.0|[20.0,5.1,3.8,1.5...|\n+---+-------------+------------+-------------+------------+-----------+--------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_tfm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59654ca8-e43c-40e4-9819-19d34b5634b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a298a27a-267f-4a61-ab36-0497ceb286c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+--------+--------------------+\n| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|Species1|            features|\n+---+-------------+------------+-------------+------------+-----------+--------+--------------------+\n|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|     0.0|[1.0,5.1,3.5,1.4,...|\n|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|     0.0|[2.0,4.9,3.0,1.4,...|\n|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|     0.0|[3.0,4.7,3.2,1.3,...|\n|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|     0.0|[4.0,4.6,3.1,1.5,...|\n|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|     0.0|[5.0,5.0,3.6,1.4,...|\n|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|     0.0|[6.0,5.4,3.9,1.7,...|\n|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|     0.0|[7.0,4.6,3.4,1.4,...|\n|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|     0.0|[8.0,5.0,3.4,1.5,...|\n|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|     0.0|[9.0,4.4,2.9,1.4,...|\n| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|     0.0|[10.0,4.9,3.1,1.5...|\n| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|     0.0|[11.0,5.4,3.7,1.5...|\n| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|     0.0|[12.0,4.8,3.4,1.6...|\n| 13|          4.8|         3.0|          1.4|         0.1|Iris-setosa|     0.0|[13.0,4.8,3.0,1.4...|\n| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|     0.0|[14.0,4.3,3.0,1.1...|\n| 15|          5.8|         4.0|          1.2|         0.2|Iris-setosa|     0.0|[15.0,5.8,4.0,1.2...|\n| 16|          5.7|         4.4|          1.5|         0.4|Iris-setosa|     0.0|[16.0,5.7,4.4,1.5...|\n| 17|          5.4|         3.9|          1.3|         0.4|Iris-setosa|     0.0|[17.0,5.4,3.9,1.3...|\n| 18|          5.1|         3.5|          1.4|         0.3|Iris-setosa|     0.0|[18.0,5.1,3.5,1.4...|\n| 19|          5.7|         3.8|          1.7|         0.3|Iris-setosa|     0.0|[19.0,5.7,3.8,1.7...|\n| 20|          5.1|         3.8|          1.5|         0.3|Iris-setosa|     0.0|[20.0,5.1,3.8,1.5...|\n+---+-------------+------------+-------------+------------+-----------+--------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_tfm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8abe7239-0632-4b90-baf0-38549b038a38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 3: Split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab870518-6478-4972-b5d9-23ee551171c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train, test = df_tfm.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8673c72b-d308-43c5-9b46-0e82d936b5d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 108 x 8\n"
     ]
    }
   ],
   "source": [
    "#Training dataset\n",
    "num_rows_train = train.count()\n",
    "num_cols_train = len(train.columns)\n",
    "print(\"Training:\",num_rows_train,\"x\",num_cols_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30fa5435-dcce-4531-aed3-1902fe48c72f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 42 x 8\n"
     ]
    }
   ],
   "source": [
    "#Testing dataset\n",
    "num_rows_test = test.count()\n",
    "num_cols_test = len(test.columns)\n",
    "print(\"Testing:\",num_rows_test,\"x\",num_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c629a48-7a59-4266-a60f-99f22bd6065f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+--------+-------------------------+-------------------------------------------------------------------------------------------------+\n|Id |SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|Species    |Species1|features                 |scaled_features                                                                                  |\n+---+-------------+------------+-------------+------------+-----------+--------+-------------------------+-------------------------------------------------------------------------------------------------+\n|1  |5.1          |3.5         |1.4          |0.2         |Iris-setosa|0.0     |[1.0,5.1,3.5,1.4,0.2,0.0]|[0.02301741350593744,6.158928408838787,8.072061621390857,0.7934616853039358,0.26206798787142,0.0]|\n|2  |4.9          |3.0         |1.4          |0.2         |Iris-setosa|0.0     |[2.0,4.9,3.0,1.4,0.2,0.0]|[0.04603482701187488,5.9174018045706,6.9189099611921625,0.7934616853039358,0.26206798787142,0.0] |\n|3  |4.7          |3.2         |1.3          |0.2         |Iris-setosa|0.0     |[3.0,4.7,3.2,1.3,0.2,0.0]|[0.06905224051781232,5.675875200302412,7.38017062527164,0.7367858506393691,0.26206798787142,0.0] |\n+---+-------------+------------+-------------+------------+-----------+--------+-------------------------+-------------------------------------------------------------------------------------------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "df_tfm.columns\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "scaler_model = scaler.fit(df_tfm)\n",
    "train=scaler_model.transform(df_tfm)\n",
    "test=scaler_model.transform(test)\n",
    "train.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9d0703b-87ce-4c38-9df3-a7373b8a02a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+--------+--------------------+--------------------+\n| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|Species1|            features|     scaled_features|\n+---+-------------+------------+-------------+------------+-----------+--------+--------------------+--------------------+\n|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|     0.0|[7.0,4.6,3.4,1.4,...|[0.16112189454156...|\n| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|     0.0|[10.0,4.9,3.1,1.5...|[0.23017413505937...|\n| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|     0.0|[11.0,5.4,3.7,1.5...|[0.25319154856531...|\n+---+-------------+------------+-------------+------------+-----------+--------+--------------------+--------------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "log=LogisticRegression(featuresCol='scaled_features',labelCol='Species1')\n",
    "lrmodel=log.fit(train)\n",
    "prediction=lrmodel.transform(test)\n",
    "test.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab00e9d-4977-4018-ba8f-c38df1a50a19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n|Species1|count|\n+--------+-----+\n|     0.0|   20|\n|     1.0|   10|\n|     2.0|   12|\n+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "test.groupby(\"Species1\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "530c3f21-2785-49f3-86c4-d63bca40f1d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n|Species1|count|\n+--------+-----+\n|     0.0|   50|\n|     1.0|   50|\n|     2.0|   50|\n+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "train.groupby(\"Species1\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84cf4102-426d-4f09-a763-668028602ff8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a26ee887-3d5a-439b-832c-170c035de011",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the MulticlassClassificationEvaluator to evaluate the model's accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Species1\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35fb7f2f-e589-4f69-b681-c5f0eb5cd907",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "lr = LogisticRegression(labelCol='Species1', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee30d997-0a9f-4dc3-aed1-d2817a53f819",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "lr_model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a765e9-6099-454f-a250-d049cfa35415",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a00f1bb-ae13-487d-9ec9-ac1d13050421",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", logistic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29c9e82a-7c83-4b8b-8125-650109888f40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Decision Tree model\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "rand=DecisionTreeClassifier(featuresCol='scaled_features',labelCol='Species1')\n",
    "rmodel=rand.fit(train)\n",
    "predictionrand=rmodel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a81310-3c20-45cc-b83b-ac4a50ab780e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "rand_accuracy = evaluator.evaluate(predictionrand)\n",
    "print(\"Accuracy:\", rand_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43d3d30f-6cbb-44df-bdf9-de6624d43749",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select the \"prediction\" and \"label\" columns\n",
    "predictions_df = predictionrand.select([\"prediction\", \"Species1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e72e688a-6eb2-453a-baa8-1891128f853e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the predictions and labels to Pandas dataframes for easier inspection\n",
    "predictions_pd = predictions_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "085a9d1a-2438-4221-ab33-3947b38f1b02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prediction  Species1\n0         0.0       0.0\n1         0.0       0.0\n2         0.0       0.0\n3         0.0       0.0\n4         0.0       0.0\n5         0.0       0.0\n6         0.0       0.0\n7         0.0       0.0\n8         0.0       0.0\n9         0.0       0.0\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 predictions and their corresponding true labels\n",
    "print(predictions_pd.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69479aed-4017-48c5-b4e9-2eac416a9b95",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 5: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1093d888-29c6-4cab-a172-98d600ff58bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the hyperparameters for the random forest model\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "regrand = RandomForestClassifier(labelCol='Species1', featuresCol='features',numTrees=100,maxDepth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e388281-b348-4cee-b6c4-c3be108703c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "regmodel = regrand.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f473737-5899-4d95-9e29-915aad256514",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = regmodel.transform(test)\n",
    "\n",
    "reg_accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", reg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab02d0c-76c0-486d-9155-c4afb267c7e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff04d202-49f7-4848-bbd8-a3276944d5e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune\n",
    "hyperparameters = [\n",
    "    {'regParam': [0.1, 0.01, 0.001], 'elasticNetParam': [0.0, 0.5, 1.0]},\n",
    "    {'regParam': [0.1, 0.01, 0.001], 'elasticNetParam': [0.0, 0.5, 1.0], 'maxIter': [10, 50, 100]}\n",
    "]\n",
    "param_grid = ParamGridBuilder().addGrid(log.regParam, hyperparameters[0]['regParam'])\\\n",
    "                               .addGrid(log.elasticNetParam, hyperparameters[0]['elasticNetParam'])\\\n",
    "                               .build()\n",
    "cv = CrossValidator(estimator=log, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=2)\n",
    "model = cv.fit(train)\n",
    "model.params\n",
    "model.bestModel\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "532187c6-da28-4331-b847-17047b58c59f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "cv_accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: \", cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec0558d-0413-48a7-98dc-9847ebbbdf56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accuracy = [logistic_accuracy,rand_accuracy,reg_accuracy,cv_accuracy]\n",
    "models = [\"logistic_reg\",\"decision_tree\",\"random_forest\",\"grid_search\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32155a4d-efdc-4613-a6e2-feb802cc64fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracy\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3c0a62a-d271-4648-8e35-67078b50bd4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n|        Model|Accuracy|\n+-------------+--------+\n| logistic_reg|     1.0|\n|decision_tree|     1.0|\n|random_forest|     1.0|\n|  grid_search|     1.0|\n+-------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "score=spark.createDataFrame(df)\n",
    "score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5a73e7f-f348-4283-a90f-00a6b5261a44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"wasbs://capstone@devassignment.blob.core.windows.net/\" + \"models/\")\n",
    "\n",
    "output_folder = \"wasbs://capstone@devassignment.blob.core.windows.net/\" + \"models/model_scores.parquet\"\n",
    "\n",
    "score.repartition(1).write.format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(output_folder)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Model training and testing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
